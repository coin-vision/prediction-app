{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT DOES BATCH COIN SEARCH OVER TREAINED MODEL\n",
    "# \n",
    "# Configs:\n",
    "# put some picture to TEST_DIR\n",
    "# add your trained model: DATA_DIR, MODEL_FILE_PATH\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import time\n",
    "import csv\n",
    "import ssl\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras import optimizers, losses, activations, models, applications\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau #, TensorBoard\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "TEST_DIR = \"/Volumes/SeagateDrive/coin-vision/_coins_for_test/\"\n",
    "\n",
    "DATA_DIR = \"/Volumes/SeagateDrive/coin-vision/data/micro-25-20190204/\"\n",
    "DATASET_FILE_NAME = DATA_DIR + 'dataset.csv'\n",
    "MODEL_LABELS_FILE_PATH = DATA_DIR + \"labels.txt\"\n",
    "MODEL_FILE_PATH = DATA_DIR + \"inception_v3_20190210-145413.hdf5\"\n",
    "\n",
    "ROWS=299\n",
    "COLS=299\n",
    "\n",
    "coinsDataset = pd.read_csv(DATASET_FILE_NAME)\n",
    "\n",
    "print(\"TEST_DIR: \" + TEST_DIR)\n",
    "print(\" \")\n",
    "print(\"MODEL_FILE_PATH: \" + MODEL_FILE_PATH)\n",
    "print(\"MODEL_LABELS_FILE_PATH: \" + MODEL_LABELS_FILE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LABELS AND TEST IMAGES\n",
    "\n",
    "# load labels from the file\n",
    "with open(MODEL_LABELS_FILE_PATH, mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    labels = {rows[0]:int(float(rows[1])) for rows in reader}\n",
    "    \n",
    "labels = labels.items()    \n",
    "\n",
    "# load test image file names\n",
    "test_images_paths = []\n",
    "for subdir, dirs, files in os.walk(TEST_DIR):\n",
    "    for file in files:\n",
    "        #print os.path.join(subdir, file)\n",
    "        filepath = subdir + os.sep + file\n",
    "        test_images_paths.append(filepath)\n",
    "        \n",
    "shuffle(test_images_paths)        \n",
    "test_images_paths = test_images_paths[0:400] # get subset of 400\n",
    "\n",
    "print('Images in test set: {}'.format(len(test_images_paths)))\n",
    "print('Labels amount: {}'.format(len(labels)))\n",
    "\n",
    "# Load test images into matrix\n",
    "\n",
    "num_images = len(test_images_paths)\n",
    "\n",
    "images_for_predict = np.zeros((num_images, 299, 299, 3))\n",
    "\n",
    "for i in range(num_images):\n",
    "    img = image.load_img(test_images_paths[i], target_size=(299, 299))\n",
    "    y = image.img_to_array(img)\n",
    "    y = np.expand_dims(y, axis=0)\n",
    "    images_for_predict[i,:,:,:] = y[:,:,:]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test images and their histograms (to see what goes to NN input)\n",
    "\n",
    "#test_img = image.load_img(test_images_paths[0])\n",
    "img_to_plot_uint8 = images_for_predict.astype(np.uint8)\n",
    "\n",
    "#plt.imshow(img_to_plot[11, :,:,:])\n",
    "#show some images from train set\n",
    "\n",
    "fig=plt.figure(figsize=(20, 20))\n",
    "columns = 4\n",
    "rows = 3\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img_to_plot_uint8[i, :,:,:]) \n",
    "    \n",
    "plt.show()\n",
    "\n",
    "plt.hist(images_for_predict[0,:,:,1].reshape(ROWS, COLS), 50, density=1, facecolor='green')\n",
    "plt.show()\n",
    "\n",
    "# move from [0, 255] to [-1, 1] range\n",
    "print('move from [0, 255] to [-1, 1] range')\n",
    "\n",
    "images_for_predict = images_for_predict/127.5 - 1.0\n",
    "\n",
    "plt.hist(images_for_predict[0,:,:,1].reshape(ROWS, COLS), 50, density=1, facecolor='green')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE AND LOAD MODEL\n",
    "\n",
    "input_shape = (ROWS, COLS, 3)\n",
    "nclass = len(labels)\n",
    "\n",
    "base_model = applications.InceptionV3(weights='imagenet', \n",
    "                                include_top=False, \n",
    "                                input_shape=(ROWS, COLS,3))\n",
    "base_model.trainable = True\n",
    "\n",
    "add_model = Sequential()\n",
    "add_model.add(base_model)\n",
    "add_model.add(GlobalAveragePooling2D())\n",
    "add_model.add(Dense(nclass, activation='softmax'))\n",
    "\n",
    "model = add_model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# LOAD MODEL\n",
    "model.load_weights(MODEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO PREDICTION\n",
    "\n",
    "images_for_predict = images_for_predict[0:200,:,:,:] # get subset for single batch prediction (no loops over batches)\n",
    "\n",
    "prediction = model.predict_classes(images_for_predict)\n",
    "label_index = {v: k for k,v in labels}\n",
    "predicts_label = [label_index[p] for p in prediction]\n",
    "print(\" prediction is done \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show: original image  |  resized original image (input to NN)  |  predicted coin\n",
    "\n",
    "print('original image  |  resized original image (input to NN)  |  predicted coin')\n",
    "\n",
    "# len(test_images_paths)\n",
    "def getImageByCoinGroupId(coinsDataset, coinGroupId):\n",
    "    coinGroupColumn = coinsDataset.loc[coinsDataset['coinGroupId'] == coinGroupId]\n",
    "    imageId = coinGroupColumn.get('imageId').values[0]\n",
    "    response = requests.get('https://d3k6u6bv48g1ck.cloudfront.net/fs/'+ imageId +'.jpg')\n",
    "    return Image.open(BytesIO(response.content))\n",
    "\n",
    "\n",
    "for i in range(len(predicts_label)):\n",
    "    # original image for prediction\n",
    "    test_img = image.load_img(test_images_paths[i])\n",
    "    # resized image for prediction\n",
    "    img = image.load_img(test_images_paths[i], target_size=(299, 299))\n",
    "    # predicted image\n",
    "    predicted_img = getImageByCoinGroupId(coinsDataset, predicts_label[i])\n",
    "    \n",
    "    fig=plt.figure(figsize=(20, 20))\n",
    "    fig.add_subplot(1, 3, 1)\n",
    "    plt.imshow(test_img)\n",
    "    fig.add_subplot(1, 3, 2)\n",
    "    plt.imshow(img)\n",
    "    fig.add_subplot(1, 3, 3)\n",
    "    plt.imshow(predicted_img)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
